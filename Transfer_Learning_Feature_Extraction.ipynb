{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulsalam-Aderoju/CNN-in-Tensorflow/blob/main/Transfer_Learning_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkF-K_oaQb3x",
        "outputId": "6a66dab7-15f7-4c4f-e10b-f732ee9437e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-18 19:30:48--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.188.48, 172.253.62.128, 172.253.115.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.188.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   114MB/s    in 1.4s    \n",
            "\n",
            "2022-07-18 19:30:50 (114 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4iTbIZfQqpj"
      },
      "outputs": [],
      "source": [
        "# Walking Through The Downloaded Data\n",
        "import os\n",
        "\n",
        "for dirpath, dirname, filename in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirname)} directories and {len(filename)} images in {dirpath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cvvxNPJSf_T"
      },
      "outputs": [],
      "source": [
        "# Set up The Data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir  = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size = IMAGE_SIZE,\n",
        "                                               batch_size = BATCH_SIZE,\n",
        "                                               class_mode = \"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = IMAGE_SIZE,\n",
        "                                             batch_size = BATCH_SIZE,\n",
        "                                             class_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZjzjCgqYtlK"
      },
      "source": [
        "# Setting up Callbacks (Things to run whilst our model trains)\n",
        "\n",
        "\n",
        "Callbacks are extra functionalities you can add to your model to be performed during or after training. Some of the most popular callbacks are:\n",
        "- Tracking experiment with the TensorBoard callback\n",
        "- Model checkpoint with the ModelCheckpoint callback\n",
        "- Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii2_MokPUpXG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "# Create A TensorBoard callback (will be functionized because we need a new one for each model)\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dirname, experiment_name):\n",
        "  log_dir = dirname + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%m%s\")\n",
        "  tensorboard_callback = tf.keras.callbacks.CSVLoggerTensorBoard(log_dir = log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUv19TYvSCSJ"
      },
      "source": [
        "# Creating Models Using Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gM2wHu9R8-Z"
      },
      "outputs": [],
      "source": [
        "# Let us compare the 2 models below:\n",
        "\n",
        "resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'\n",
        "efficient_net = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxOICOKqZC7V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d78oh72eZQgl"
      },
      "outputs": [],
      "source": [
        "def create_model(model_url, classes):\n",
        "\n",
        "  # Donwload Pretrained model and save it as keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url, \n",
        "                                           trainable = False, # Freeze already learned patterns\n",
        "                                           name = 'feature_extraction_layer', \n",
        "                                           input_shape = IMAGE_SIZE + (3,))\n",
        "  \n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    layers.Dense(classes, activation = \"softmax\", name = \"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa5hOEgMblvq"
      },
      "source": [
        "## Creating and testing ResNet Tensorflow Hub Feature Extraction Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGgGmMiQbiJ6"
      },
      "outputs": [],
      "source": [
        "# Create ResNet Model\n",
        "resnet_model = create_model(resnet_url, classes = train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile our resnet model\n",
        "resnet_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "resnet_history = resnet_model.fit(train_data_10_percent, epochs = 5, steps_per_epoch = len(train_data_10_percent),\n",
        "                             validation_data = test_data, validation_steps = len(test_data),\n",
        "                             callbacks = [create_tensorboard_callback(dirname = 'tensorflow_hub',\n",
        "                                                                      experiment_name = \"Resnet50v2\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtwTSRhkrZys"
      },
      "source": [
        "## Evaluating Our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaJN6i-QcX2x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(resnet_history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTb900zXdZ0p"
      },
      "outputs": [],
      "source": [
        "# Plotting Loss curves for the model\n",
        "def plot_curves(history):\n",
        "  epochs = range(len(resnet_history.history[\"loss\"]))\n",
        "\n",
        "  # LOSSES\n",
        "  training_loss = resnet_history.history[\"loss\"]\n",
        "  val_loss = resnet_history.history[\"val_loss\"]\n",
        "\n",
        "  #ACCURACIES\n",
        "  training_acc = resnet_history.history[\"accuracy\"]\n",
        "  val_acc = resnet_history.history[\"val_accuracy\"]\n",
        "\n",
        "\n",
        "  #PLOT LOSSES  \n",
        "  plt.figure() \n",
        "  plt.plot(epochs, training_loss, label = \"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label = \"val_loss\")\n",
        "  plt.title(\"Losses\")\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  #PLOT ACCURACIES\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, training_acc, label = \"training_acc\")\n",
        "  plt.plot(epochs, val_acc, label = \"val_acc\")\n",
        "  plt.title(\"Accuracies\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history = resnet_history)"
      ],
      "metadata": {
        "id": "B2JXxmzNB0zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating and testing EfficientNet Tensorflow Hub Feature Extraction Model"
      ],
      "metadata": {
        "id": "eETRLXyMBZG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, classes):\n",
        "  # Pretrained\n",
        "  feature_extractor = hub.KerasLayer(model_url, \n",
        "                                     trainable = False,\n",
        "                                     name = \"feature_extraction_layer\",\n",
        "                                     input_shape =IMAGE_SIZE + (3,))\n",
        "  # Our own\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor,\n",
        "      tf.keras.layers.Dense(classes, activation = \"softmax\", name = \"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zLQjM2roA6DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = create_model(model_url = efficient_net,\n",
        "                                  classes = train_data_10_percent.num_classes)\n",
        "\n",
        "efficientnet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                           optimizer = tf.keras.optimizers.Adam(),\n",
        "                           metrics = [\"accuracy\"])\n",
        "\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent, epochs = 5, steps_per_epoch = len(train_data_10_percent),\n",
        "                       validation_data = test_data, validation_steps = len(test_data),\n",
        "                       callbacks= [create_tensorboard_callback(dirname = \"tensorflow_hub\",\n",
        "                                                               experiment_name = \"EfficientnetB0\")])"
      ],
      "metadata": {
        "id": "y108Sf7GDSiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Different types of transfer learning\n",
        "**\"As is\" transfer learning -** using an existing model with no changes what so ever (e.g using ImageNet model on 1000 ImageNet classes, none of your own)\n",
        "\n",
        "**\"Feature extraction\" transfer learning -** use the prelearned patterns of an existing model (e.g. EfficientNetB0 trained on ImageNet) and adjust the output layer for your own problem (e.g. 1000 classes -> 10 classes of food)\n",
        "\n",
        "**\"Fine-tuning\" transfer learning -** use the prelearned patterns of an existing model and \"fine-tune\" many or all of the underlying layers (including new output layers)\n"
      ],
      "metadata": {
        "id": "df85NUrWUTv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Our Model's result using TensorBoard"
      ],
      "metadata": {
        "id": "zUCK5C3IWARf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**ðŸ”‘ Note:** When you upload things to TensorBoard.dev, you experiments are public. So if you're running private experiments (things you don't want others to see) do not upload them to TensorBoard.dev."
      ],
      "metadata": {
        "id": "Dc80VzUcWIbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload Tensorboard dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/\\\n",
        "  --name \"EfficientB0 vs ResNet50V2\"\\\n",
        "  --description \"Comparing 2 different TF Hub feature extraction architectures using 10% of training data\"\\\n",
        "  --one_shot"
      ],
      "metadata": {
        "id": "-NaUuUVXEb14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out my Tensorboard experiments\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "GnxQG1zvZ89k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n4hNAtFueoI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transfer-Learning-Feature-Extraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+IdXD4FPR8knBiPG8ZvaN",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}